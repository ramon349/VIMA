{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40266c3f-eb7c-4d04-9ac5-af336af80e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb \n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from vima.utils import *\n",
    "from vima_bench import make,PARTITION_TO_SPECS\n",
    "from vima import create_policy_from_ckpt\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "from glob import glob \n",
    "import pickle as pkl \n",
    "from PIL import Image \n",
    "from example import prepare_prompt,prepare_obs\n",
    "import torch \n",
    "from torch.optim import Adam \n",
    "from vima.policy.vima_policy  import VIMAPolicy \n",
    "from pathlib import Path \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from vima.trajectory.trajectory_dataset import TrajectoryLoader\n",
    "from collections import defaultdict\n",
    "from behavior_cloning_batched import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d24ad0a-68e7-4deb-9b92-168419aebf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "summary_dir =\"/home/rlcorrea/CSE574_project_vima/model_logs_demo\"\n",
    "#Path to the trajectories \n",
    "traj_folder = \"/scratch/rlcorrea/vima_v6/rearrange_then_restore/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f773820c-3959-49e6-971f-822d6658bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = TrajectoryLoader(\n",
    "    traj_folder=traj_folder,\n",
    "    traj_name=\"rearrange_then_restore\",\n",
    "    n_workers=2,\n",
    "    batch_size=2,\n",
    "    n_epochs=1,\n",
    "    max_queue_size=20,\n",
    ")\n",
    "device = 'cuda:0'\n",
    "#This are the  parameters for the  model used in the 2M configuration \n",
    "vima_config = {'embed_dim': 256, 'xf_n_layers': 1, 'sattn_n_heads': 8, 'xattn_n_heads': 8}\n",
    "policy =  VIMAPolicy(**vima_config) \n",
    "weight_path = \"/home/rlcorrea/CSE574_project_vima/model_weights/2M.ckpt\"\n",
    "ckpt = torch.load(weight_path,map_location=device) \n",
    "#load the pretrained model except for the policy agents weight. The action prediction is handeled by the cross attention_gpt \n",
    "policy.load_state_dict({k.replace('policy.',\"\"):v for k,v in ckpt['state_dict'].items() if 'xattn_gpt' not in k},strict=False)\n",
    "policy = policy.train()\n",
    "writer,weight_path = init_summary_writter(summary_dir)\n",
    "#make it so only the cross attention component is trainable \n",
    "for n,e in policy.named_parameters(): \n",
    "    e.requires_grad = False \n",
    "for n,e in policy.xattn_gpt.named_parameters(): \n",
    "    e.requires_grad = True \n",
    "policy = policy.to(device)\n",
    "opti = Adam(policy.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f3be5b-ab2a-4cde-81ff-31a1195e6e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    }
   ],
   "source": [
    "for traj_ids,observations,actions ,prompt_infos ,trajectory_steps, in dl: \n",
    "    num_batches = len(prompt_infos)\n",
    "    opti.zero_grad()\n",
    "    total_loss =0 \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74d7a4b-baac-41a0-8246-bfade8028506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vima import utils as vima_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79512228-f77b-48ed-97b1-b1382548da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cropped_img', 'bbox', 'mask'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_infos[0][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a70905d-a06a-4209-bd40-d88540dc2602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 419,  291, 5517, 4820,   12,   48, 5818,   11,  258, 7882,    5,    1],\n",
       "        [ 419,  291, 5517, 4820,   12,   48, 5818,   11,  258, 7882,    5,    1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(word_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95ea7604-b24a-4290-b2ab-69b1a941ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prompts = [e[0] for e in prompt_infos] \n",
    "word_batch = torch.stack([e[1].to(device) for e in prompt_infos ]) \n",
    "image_batches =[e[2].to_torch_tensor(device=device) for e in prompt_infos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ace38c8-54cf-4381-8576-8bf2fa0530ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataDict {\n",
       "   cropped_img: DataDict {\n",
       "     front: tensor([[[[[  0,   0,  25,  ..., 129,   0,   0],\n",
       "                [  0,   0,  25,  ..., 128,   0,   0],\n",
       "                [  0,   0,  25,  ..., 129,   0,   0],\n",
       "                ...,\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0]],\n",
       "     \n",
       "               [[  0,   0,  25,  ...,  44,   0,   0],\n",
       "                [  0,   0,  25,  ...,  44,   0,   0],\n",
       "                [  0,   0,  25,  ...,  43,   0,   0],\n",
       "                ...,\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0]],\n",
       "     \n",
       "               [[  0,   0,  25,  ...,  45,   0,   0],\n",
       "                [  0,   0,  25,  ...,  45,   0,   0],\n",
       "                [  0,   0,  25,  ...,  45,   0,   0],\n",
       "                ...,\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0],\n",
       "                [  0,   0,  25,  ...,  25,   0,   0]]],\n",
       "     \n",
       "     \n",
       "              [[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                ...,\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "     \n",
       "               [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                ...,\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "     \n",
       "               [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                ...,\n",
       "                [ 47,  47,  47,  ...,  47,  47,  47],\n",
       "                [ 36,  36,  36,  ...,  36,  36,  36],\n",
       "                [  0,   0,   0,  ...,   0,   0,   0]]]]], device='cuda:0',\n",
       "            dtype=torch.uint8),\n",
       "     top: tensor([[[[[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                ...,\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "     \n",
       "               [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                ...,\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "     \n",
       "               [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                ...,\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]]],\n",
       "     \n",
       "     \n",
       "              [[[47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0]],\n",
       "     \n",
       "               [[47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0]],\n",
       "     \n",
       "               [[47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0],\n",
       "                [47, 47, 47,  ..., 47, 36,  0]]]]], device='cuda:0',\n",
       "            dtype=torch.uint8),\n",
       "   },\n",
       "   bbox: DataDict {\n",
       "     front: tensor([[[169,  86,  25,  21],\n",
       "              [200,  56,  23,  25]]], device='cuda:0'),\n",
       "     top: tensor([[[169,  82,  27,  21],\n",
       "              [200,  39,  25,  24]]], device='cuda:0'),\n",
       "   },\n",
       "   mask: DataDict {\n",
       "     front: tensor([[True, True]], device='cuda:0'),\n",
       "     top: tensor([[True, True]], device='cuda:0'),\n",
       "   },\n",
       " },\n",
       " DataDict {\n",
       "   cropped_img: DataDict {\n",
       "     front: tensor([[[[[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 3,  3,  3,  ...,  3,  3,  3],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [ 4,  4,  4,  ...,  4,  4,  4],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "     \n",
       "               [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 3,  3,  3,  ...,  3,  3,  3],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [ 4,  4,  4,  ...,  4,  4,  4],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]],\n",
       "     \n",
       "               [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 3,  3,  3,  ...,  3,  3,  3],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [ 4,  4,  4,  ...,  4,  4,  4],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "                [ 0,  0,  0,  ...,  0,  0,  0]]]]], device='cuda:0',\n",
       "            dtype=torch.uint8),\n",
       "     top: tensor([[[[[47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47]],\n",
       "     \n",
       "               [[47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47]],\n",
       "     \n",
       "               [[47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                ...,\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47],\n",
       "                [47, 47, 47,  ..., 47, 47, 47]]]]], device='cuda:0',\n",
       "            dtype=torch.uint8),\n",
       "   },\n",
       "   bbox: DataDict {\n",
       "     front: tensor([[[154,  56,  27,  32]]], device='cuda:0'),\n",
       "     top: tensor([[[154,  40,  30,  30]]], device='cuda:0'),\n",
       "   },\n",
       "   mask: DataDict {\n",
       "     front: tensor([[True]], device='cuda:0'),\n",
       "     top: tensor([[True]], device='cuda:0'),\n",
       "   },\n",
       " }]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b9ab3-38e3-4bc3-bc23-bfb6c77bb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The main challenge with this data is that there is no way for me to identify a way to forward "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_vima",
   "language": "python",
   "name": "my_vima"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
